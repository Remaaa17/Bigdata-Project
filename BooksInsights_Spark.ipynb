{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9df6d2e1-3d84-4947-ad36-e15a13ea3c57",
   "metadata": {},
   "source": [
    "## Create A spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "efaf3037-828c-4ca7-87df-771af707ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  pyspark.sql import SparkSession\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import countDistinct\n",
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e2acdc89-5208-40f7-965f-9628847bec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"My_Spark_Project\")\\\n",
    ".config(\"spark.memory.offHeap. enabled\", \"true\") . config(\"spark.memory.offHeap. size\", \"30g\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8de9f67-6e95-4eaa-bb70-929883a26f58",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    " **Tip**: In this section of the report, you will load in the data, check for cleanliness, and then trim and clean your dataset for analysis. Make sure that you document your steps carefully and justify your cleaning decisions. We will start with addressing General properities about the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "33ab1acf-e3cf-41f6-9ce0-3a53ac5a2f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\abdel\\Downloads\\books_data.csv (1)\\books_data.csv\"\n",
    "# Read the CSV file into a DataFrame\n",
    "books_df = spark.read.csv(file_path, header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f457f1-017d-4b93-8e55-62ded7c15696",
   "metadata": {},
   "source": [
    "### General Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5997300-38e0-44f0-9782-b2b16b896920",
   "metadata": {},
   "source": [
    "> **Show Books Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8d98394a-c2ef-40e6-a01a-aaebf001d9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|               Title|         description|             authors|               image|         previewLink|           publisher|       publishedDate|            infoLink|          categories|        ratingsCount|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Its Only Art If I...|                null|    ['Julie Strain']|http://books.goog...|http://books.goog...|                null|                1996|http://books.goog...|['Comics & Graphi...|                null|\n",
      "|Dr. Seuss: Americ...|\"Philip Nel takes...| like that of Lew...| has changed lang...| giving us new wo...| inspiring artist...|      ['Philip Nel']|http://books.goog...|http://books.goog...|           A&C Black|\n",
      "|Wonderful Worship...|This resource inc...|    ['David R. Ray']|http://books.goog...|http://books.goog...|                null|                2000|http://books.goog...|        ['Religion']|                null|\n",
      "|Whispers of the W...|Julia Thomas find...| ['Veronica Haddon']|http://books.goog...|http://books.goog...|           iUniverse|             2005-02|http://books.goog...|         ['Fiction']|                null|\n",
      "|Nation Dance: Rel...|                null|     ['Edward Long']|                null|http://books.goog...|                null|          2003-03-01|http://books.goog...|                null|                null|\n",
      "|The Church of Chr...|In The Church of ...|['Everett Ferguson']|http://books.goog...|http://books.goog...|Wm. B. Eerdmans P...|                1996|http://books.goog...|        ['Religion']|                 5.0|\n",
      "|The Overbury affa...|                null|['Miriam Allen De...|                null|http://books.goog...|                null|                1960|http://books.goog...|                null|                null|\n",
      "|A Walk in the Woo...|                null|    ['Lee Blessing']|                null|http://books.goog...|                null|                1988|http://books.goog...|                null|                 3.0|\n",
      "|Saint Hyacinth of...|The story for chi...|['Mary Fabyan Win...|http://books.goog...|http://books.goog...|     Tan Books & Pub|          2009-01-01|http://books.goog...|['Biography & Aut...|                null|\n",
      "|Rising Sons and D...|Wardell recalls h...|  ['Steven Wardell']|                null|http://books.goog...|  Plympton PressIntl|                1995|http://books.goog...|  ['Social Science']|                null|\n",
      "|Muslim Women's Ch...|Counters the West...|['Camillia Fawzi ...|http://books.goog...|http://books.goog...|    Berg Pub Limited|          1994-02-17|http://books.goog...|        ['Religion']|                null|\n",
      "|Dramatica for Scr...|Dramatica for Scr...|['Armando Salda A...|http://books.goog...|http://books.goog...|                null|             2005-07|http://books.goog...|       ['Reference']|                null|\n",
      "|Mensa Number Puzz...|Acclaimed teacher...|['Evelyn B. Chris...|http://books.goog...|http://books.goog...|            Sky Pony|          2018-11-06|http://books.goog...|['Juvenile Nonfic...|                null|\n",
      "|Vector Quantizati...|\"Herb Caen, a pop...| but the statemen...|              i. e. | data compression...|               audio|              images| and video signal...|['Allen Gersho', ...|http://books.goog...|\n",
      "|A husband for Kutani|First published i...|      ['Frank Owen']|http://books.goog...|http://books.goog...|Pickle Partners P...|          2018-02-27|https://play.goog...|         ['History']|                null|\n",
      "| Gold and greenstone|Sally did most th...|     ['Barry Crump']|                null|http://books.goog...|                null|                2009|http://books.goog...|['New Zealand fic...|                null|\n",
      "|\"The Ultimate Gui...|This collection b...|    ['Fiona Cownie']|http://books.goog...|http://books.goog...|Bloomsbury Publis...|          2010-01-28|https://play.goog...|             ['Law']|                null|\n",
      "|The Repeal of Ret...|\"At a time when A...|       sex educators| and novelists—fr...| Gurstein offers ...|['Rochelle Gurste...|http://books.goog...|http://books.goog...|       Hill and Wang|          2016-01-05|\n",
      "|Overcoming Hypert...|Like a time bomb ...|['Kenneth H. Coop...|http://books.goog...|http://books.goog...|              Bantam|          2012-02-01|https://play.goog...|['Health & Fitness']|                null|\n",
      "|    Alaska Sourdough|\"\"\"Sourdough is a...| as author Ruth A...| this book includ...| three days to on...| there are more t...| loads of time-te...| and plenty of lo...| there are recipe...|     ['Ruth Allman']|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "45ddf24d-afc8-479a-9470-a9c0e86298bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Title: string (nullable = true)\n",
      " |-- description: string (nullable = false)\n",
      " |-- authors: string (nullable = false)\n",
      " |-- image: string (nullable = false)\n",
      " |-- previewLink: string (nullable = false)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- publishedDate: string (nullable = true)\n",
      " |-- infoLink: string (nullable = false)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- ratingsCount: string (nullable = true)\n",
      "\n",
      "Count of dataframe: 212404\n"
     ]
    }
   ],
   "source": [
    "books_data_df.printSchema()\n",
    "print(\"Count of dataframe:\",books_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5be8f440-63a0-40b5-b5bb-e5ab8cf84d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|summary|               Title|         description|             authors|               image|         previewLink|           publisher|       publishedDate|            infoLink|          categories|        ratingsCount|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  count|              212403|              144047|              181153|              161213|              188349|              139274|              186560|              188103|              171880|               63852|\n",
      "|   mean|   3823.672941176471|  1.4285714285714286|              1578.4|              1184.0|            Infinity|             3734.75|   1982.702933143332|   1989.054693877551|  1983.7334777898159|   56.31520537852275|\n",
      "| stddev|  10717.999589636447|  0.9759000729485332|  1278.7901502106834|   959.3546076180041|                 NaN|  10193.316327911616|   37.65620052385513|   94.83861134693093|  142.43423125699238|  329.20879859753734|\n",
      "|    min|  \"\"\" Film technique|              \"\" and| \"\" \"\"I'm a Littl...| \"\" \"\"In Honor of...| \"\" \"\"The Barefoo...| \"\" \"\"Skipper Ire...| \"\" \"\"Cruising fo...| \"\" Rawlins says....| \"\" Knox's quirky...| !Buscalo!'s easy...|\n",
      "|    max|you can do anythi...|�Una novela llam�...|” “Jeanie with th...|” “sexual napalm…...|” headlines eight...|                펜립|” which is anthol...|        秀和システム|�� folk art is a ...|              谷月社|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06608616-e7f0-490f-8ba5-8a2eaf1a8be2",
   "metadata": {},
   "source": [
    "> **Apply ETL => Transform Step** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b6b3bb59-5c4b-4988-90c9-886628f93e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Title: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- image: string (nullable = true)\n",
      " |-- previewLink: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- publishedDate: string (nullable = true)\n",
      " |-- infoLink: string (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- ratingsCount: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "# Assuming books_data_df is your DataFrame\n",
    "books_df = books_df.withColumn(\"ratingsCount\", col(\"ratingsCount\").cast(\"float\"))\n",
    "# Check the schema to verify the data type conversion\n",
    "books_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "39cbc43d-976c-4902-b67a-c170f82498f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[Title: string, description: string, authors: string, image: string, preview_Link: string, publisher: string, publishedDate: string, info_Link: string, categories: string, ratingsCount: float]\n"
     ]
    }
   ],
   "source": [
    "books_df = books_df.withColumnRenamed('previewLink', 'preview_Link') \\\n",
    "                     .withColumnRenamed('infoLink', 'info_Link')\n",
    "\n",
    "print (books_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31eb1bd5-0f87-40ab-84df-73115b8ff5e1",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b54c56c-112a-4a93-a32e-31ecc51ef9b0",
   "metadata": {},
   "source": [
    "> **Check Null values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3fcab13e-c870-4e2e-992f-f93c5abfb103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null count in 'Title': 1\n",
      "Null count in 'description': 68357\n",
      "Null count in 'authors': 31251\n",
      "Null count in 'image': 51191\n",
      "Null count in 'preview_Link': 24055\n",
      "Null count in 'publisher': 73130\n",
      "Null count in 'publishedDate': 25844\n",
      "Null count in 'info_Link': 24301\n",
      "Null count in 'categories': 40524\n",
      "Null count in 'ratingsCount': 168972\n"
     ]
    }
   ],
   "source": [
    "columns_to_check = books_df.columns\n",
    "# Count null values in each column\n",
    "null_counts = books_df.agg(*[spark_sum(col(c).isNull().cast(\"int\")).alias(c + '_null_count') for c in columns_to_check])\n",
    "\n",
    "# Collect the result as a single row\n",
    "null_counts_single_row = null_counts.collect()[0]\n",
    "\n",
    "# Show the null counts\n",
    "for col_name in columns_to_check:\n",
    "    print(f\"Null count in '{col_name}': {null_counts_single_row[col_name + '_null_count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0a93ee7e-36d0-4b86-beae-933bb0257e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent value in column 'Title': \"\"\"Mom\n",
      "Most frequent value in column 'description': Not Available\n",
      "Most frequent value in column 'authors': Unknown\n",
      "Most frequent value in column 'image': Not Available\n",
      "Most frequent value in column 'previewLink': Not Available\n",
      "Most frequent value in column 'publisher': None\n",
      "Most frequent value in column 'publishedDate': None\n",
      "Most frequent value in column 'infoLink': Not Available\n",
      "Most frequent value in column 'categories': None\n",
      "Most frequent value in column 'ratingsCount': None\n"
     ]
    }
   ],
   "source": [
    "# List of columns to find most frequent values\n",
    "cols_to_check = [\"Title\", \"description\", \"authors\", \"image\", \"previewLink\", \"publisher\", \"publishedDate\", \"infoLink\", \"categories\", \"ratingsCount\"]\n",
    "\n",
    "# Find the most frequent value in each column\n",
    "most_frequent_values = []\n",
    "for col_name in cols_to_check:\n",
    "    mode_value = books_data_df.groupBy(col_name).count().orderBy(col(\"count\").desc()).select(col_name).first()[0]\n",
    "    most_frequent_values.append((col_name, mode_value))\n",
    "\n",
    "# Print the most frequent value in each column\n",
    "for col_name, value in most_frequent_values:\n",
    "    print(f\"Most frequent value in column '{col_name}': {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c87d902-bd21-4da9-9422-a89f1c8faed3",
   "metadata": {},
   "source": [
    "> **Fill Null values**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d226b34-6689-4d81-b4ee-b8c5bcbac02f",
   "metadata": {},
   "source": [
    "* Fill numerical col with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d2c391a0-89cb-4229-818c-14e4eb088d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, when\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(inputCols=['ratingsCount'], outputCols=['ratingsCount']).setStrategy(\"mean\")\n",
    "books_df = imputer.fit(books_df).transform(books_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4d8d578f-7b38-45bd-b6bc-f81a5f3279d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with a default value\n",
    "default_value = \"Unknown\"\n",
    "books_df = books_df.fillna(default_value, subset=[ 'publisher','authors','categories'])\n",
    "default_value2 = \"Not Available\"\n",
    "books_df = books_df.fillna(default_value2, subset=['image', 'preview_Link', 'info_Link', 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2622e983-e136-494b-9b8a-1ac866b50c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import substring, col\n",
    "books_df = books_df.withColumn('Year', substring(col('publishedDate'), 1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fa0e02-d096-4a23-b374-e5f84a680292",
   "metadata": {},
   "source": [
    "> **Drop Null values in these coloumns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "03df34f9-d5fe-4110-b779-23e402a53be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df= books_df.dropna(subset=['Title'])\n",
    "books_df = books_df.dropna(subset=['Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ae245023-f200-43b7-8249-2ef6d0ab4c76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null percentage in column 'Title': 0.00%\n",
      "Null percentage in column 'description': 0.00%\n",
      "Null percentage in column 'authors': 0.00%\n",
      "Null percentage in column 'image': 0.00%\n",
      "Null percentage in column 'preview_Link': 0.00%\n",
      "Null percentage in column 'publisher': 0.00%\n",
      "Null percentage in column 'publishedDate': 0.00%\n",
      "Null percentage in column 'info_Link': 0.00%\n",
      "Null percentage in column 'categories': 0.00%\n",
      "Null percentage in column 'ratingsCount': 0.00%\n",
      "Null percentage in column 'Year': 0.00%\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "total_rows = books_df.count()\n",
    "null_percentages = []\n",
    "for col_name in books_df.columns:\n",
    "    null_count = books_df.where(col(col_name).isNull()).count()\n",
    "    null_percentage = (null_count / total_rows) * 100\n",
    "    null_percentages.append((col_name, null_percentage))\n",
    "\n",
    "# Print null percentages\n",
    "for col_name, percentage in null_percentages:\n",
    "    print(f\"Null percentage in column '{col_name}': {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86d7ef0-9841-42a5-9434-488009e60d81",
   "metadata": {},
   "source": [
    "> **Drop unused col**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "27a611b9-1333-4896-9b1c-5f62b07c31e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Title: string (nullable = true)\n",
      " |-- description: string (nullable = false)\n",
      " |-- authors: string (nullable = false)\n",
      " |-- image: string (nullable = false)\n",
      " |-- preview_Link: string (nullable = false)\n",
      " |-- publisher: string (nullable = false)\n",
      " |-- info_Link: string (nullable = false)\n",
      " |-- categories: string (nullable = false)\n",
      " |-- ratingsCount: float (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'publishedDate' column\n",
    "books_df = books_df.drop('publishedDate')\n",
    "# Check the schema to verify the column has been dropped\n",
    "books_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa5a3f1-0a02-459a-98ca-14dd62c26b44",
   "metadata": {},
   "source": [
    "> **check Dublication** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "96c56bae-e6dd-4afb-9099-4caf123fa74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before drop dublication: 186559\n",
      "After drop dublication: 186559\n"
     ]
    }
   ],
   "source": [
    "print(\"Before drop dublication:\",books_df.count())\n",
    "books_df.dropDuplicates()\n",
    "print(\"After drop dublication:\",books_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9174162e-1fa1-4ca5-85ad-21407264aea4",
   "metadata": {},
   "source": [
    "> **Show of data after cleanning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "255f7847-ab5a-4d80-88ef-c51df031b699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------+----+\n",
      "|               Title|         description|             authors|               image|        preview_Link|           publisher|           info_Link|          categories|ratingsCount|Year|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------+----+\n",
      "|Its Only Art If I...|       Not Available|    ['Julie Strain']|http://books.goog...|http://books.goog...|             Unknown|http://books.goog...|['Comics & Graphi...|   56.315205|1996|\n",
      "|Dr. Seuss: Americ...|\"Philip Nel takes...| like that of Lew...| has changed lang...| giving us new wo...| inspiring artist...|http://books.goog...|http://books.goog...|   56.315205|['Ph|\n",
      "|Wonderful Worship...|This resource inc...|    ['David R. Ray']|http://books.goog...|http://books.goog...|             Unknown|http://books.goog...|        ['Religion']|   56.315205|2000|\n",
      "|Whispers of the W...|Julia Thomas find...| ['Veronica Haddon']|http://books.goog...|http://books.goog...|           iUniverse|http://books.goog...|         ['Fiction']|   56.315205|2005|\n",
      "|Nation Dance: Rel...|       Not Available|     ['Edward Long']|       Not Available|http://books.goog...|             Unknown|http://books.goog...|             Unknown|   56.315205|2003|\n",
      "|The Church of Chr...|In The Church of ...|['Everett Ferguson']|http://books.goog...|http://books.goog...|Wm. B. Eerdmans P...|http://books.goog...|        ['Religion']|         5.0|1996|\n",
      "|The Overbury affa...|       Not Available|['Miriam Allen De...|       Not Available|http://books.goog...|             Unknown|http://books.goog...|             Unknown|   56.315205|1960|\n",
      "|A Walk in the Woo...|       Not Available|    ['Lee Blessing']|       Not Available|http://books.goog...|             Unknown|http://books.goog...|             Unknown|         3.0|1988|\n",
      "|Saint Hyacinth of...|The story for chi...|['Mary Fabyan Win...|http://books.goog...|http://books.goog...|     Tan Books & Pub|http://books.goog...|['Biography & Aut...|   56.315205|2009|\n",
      "|Rising Sons and D...|Wardell recalls h...|  ['Steven Wardell']|       Not Available|http://books.goog...|  Plympton PressIntl|http://books.goog...|  ['Social Science']|   56.315205|1995|\n",
      "|Muslim Women's Ch...|Counters the West...|['Camillia Fawzi ...|http://books.goog...|http://books.goog...|    Berg Pub Limited|http://books.goog...|        ['Religion']|   56.315205|1994|\n",
      "|Dramatica for Scr...|Dramatica for Scr...|['Armando Salda A...|http://books.goog...|http://books.goog...|             Unknown|http://books.goog...|       ['Reference']|   56.315205|2005|\n",
      "|Mensa Number Puzz...|Acclaimed teacher...|['Evelyn B. Chris...|http://books.goog...|http://books.goog...|            Sky Pony|http://books.goog...|['Juvenile Nonfic...|   56.315205|2018|\n",
      "|Vector Quantizati...|\"Herb Caen, a pop...| but the statemen...|              i. e. | data compression...|               audio| and video signal...|['Allen Gersho', ...|   56.315205| ima|\n",
      "|A husband for Kutani|First published i...|      ['Frank Owen']|http://books.goog...|http://books.goog...|Pickle Partners P...|https://play.goog...|         ['History']|   56.315205|2018|\n",
      "| Gold and greenstone|Sally did most th...|     ['Barry Crump']|       Not Available|http://books.goog...|             Unknown|http://books.goog...|['New Zealand fic...|   56.315205|2009|\n",
      "|\"The Ultimate Gui...|This collection b...|    ['Fiona Cownie']|http://books.goog...|http://books.goog...|Bloomsbury Publis...|https://play.goog...|             ['Law']|   56.315205|2010|\n",
      "|The Repeal of Ret...|\"At a time when A...|       sex educators| and novelists—fr...| Gurstein offers ...|['Rochelle Gurste...|http://books.goog...|       Hill and Wang|   56.315205|http|\n",
      "|Overcoming Hypert...|Like a time bomb ...|['Kenneth H. Coop...|http://books.goog...|http://books.goog...|              Bantam|https://play.goog...|['Health & Fitness']|   56.315205|2012|\n",
      "|    Alaska Sourdough|\"\"\"Sourdough is a...| as author Ruth A...| this book includ...| three days to on...| there are more t...| and plenty of lo...| there are recipe...|   56.315205| loa|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50e094b-4354-4658-9991-fb36c68178f1",
   "metadata": {},
   "source": [
    "#### Some Insigths From data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "46e71eaa-0d87-4555-9c77-b70a336ffb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|             authors|count|\n",
      "+--------------------+-----+\n",
      "|  ['Barbara Melosh']|    1|\n",
      "|    ['Donald Cline']|    1|\n",
      "|     ['Dian Layton']|    2|\n",
      "| ['Sergius Golowin']|    1|\n",
      "|       ['Kotoyama,']|    1|\n",
      "|   ['Joseph Kerman']|    1|\n",
      "|     ['Kay Flowers']|    1|\n",
      "|     ['John Rewald']|    3|\n",
      "|\"\" To a very stro...|    1|\n",
      "|['I. Ristic', 'Ia...|    1|\n",
      "|['Andrew P. Tobias']|    3|\n",
      "|['Judith Ennamora...|    2|\n",
      "|['Jamgon Kongtrul...|    1|\n",
      "|['Frank Miller', ...|    1|\n",
      "|['National Resear...|    1|\n",
      "| all of whom were...|    1|\n",
      "|['William B. Park...|    1|\n",
      "|      ['Max Fogiel']|    3|\n",
      "|      ['Jules Bass']|    1|\n",
      "|  ['Rebecca Harvin']|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|           publisher|count|\n",
      "+--------------------+-----+\n",
      "|        Lorenz Books|   22|\n",
      "|       The New Press|   15|\n",
      "|Janes Information...|    7|\n",
      "|National Committe...|    1|\n",
      "|            Capstone|   81|\n",
      "|          Soma Books|    5|\n",
      "| perhaps the most...|    1|\n",
      "|University Roches...|   16|\n",
      "| and through his ...|    2|\n",
      "|http://books.goog...|    1|\n",
      "|      Celestial Arts|   39|\n",
      "|French & European...|    2|\n",
      "|Arcadia Publishin...|    3|\n",
      "| and cultural iss...|    1|\n",
      "|   Ssar Publications|    1|\n",
      "|    Random House LLC|   11|\n",
      "|['Joseph Henry Ja...|    2|\n",
      "|http://books.goog...|    1|\n",
      "|  Instructional Fair|    8|\n",
      "|['Erwin Schroding...|    2|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_df.groupBy(\"authors\").count().show()\n",
    "books_df.groupBy(\"publisher\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8441bf87-9fe2-4fc6-9aaf-e6dec03b141c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|unique_Titles|\n",
      "+-------------+\n",
      "|       186555|\n",
      "+-------------+\n",
      "\n",
      "+-----------------+\n",
      "|unique_categories|\n",
      "+-----------------+\n",
      "|            27802|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "# Count the number of unique states\n",
    "unique_states_df = books_df.agg(F.countDistinct(\"Title\").alias(\"unique_Titles\"))\n",
    "unique_states_df.show()\n",
    "# Count the number of unique cities\n",
    "unique_cities_df = books_df.agg(F.countDistinct(\"categories\").alias(\"unique_categories\"))\n",
    "unique_cities_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6e8fb91c-75bc-4704-868e-8168e0000f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               Title|count|\n",
      "+--------------------+-----+\n",
      "|Isaac Asimov: Mas...|    1|\n",
      "|     White Rock Ways|    1|\n",
      "|The Face of the T...|    1|\n",
      "|     Iridescent Soul|    1|\n",
      "|L'Alchimiste (Cof...|    1|\n",
      "|  The Book of Garlic|    1|\n",
      "|A Jesse Stuart Ha...|    1|\n",
      "|      Badenheim 1939|    1|\n",
      "|        Pagan Babies|    1|\n",
      "|The Self and its ...|    1|\n",
      "|The Educated Chil...|    1|\n",
      "|Future Perfect - ...|    1|\n",
      "|The cornet of hor...|    1|\n",
      "|Basic Arabic Work...|    1|\n",
      "|Organizational Th...|    1|\n",
      "|Oz and Beyond: Th...|    1|\n",
      "|Fundamentals of I...|    1|\n",
      "|We Love Baseball!...|    1|\n",
      "|... Marine Mollus...|    1|\n",
      "|Surviving Childho...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------------------+-----+\n",
      "|            categories|count|\n",
      "+----------------------+-----+\n",
      "|   Toronto Globe an...|    1|\n",
      "|       ['Arboviruses']|    1|\n",
      "|  \"[\"\"Children's so...|   10|\n",
      "|   Gopnik shows tha...|    1|\n",
      "|  ['Melanchthon, Ph...|    1|\n",
      "|   and always naked...|    1|\n",
      "|       ['Contentment']|    1|\n",
      "|          ['Barbados']|    2|\n",
      "|  https://play.goog...|    1|\n",
      "|       ['Art, Modern']|   15|\n",
      "|   the Kongo of Low...|    1|\n",
      "|  http://books.goog...|    1|\n",
      "|  ['Boats and boati...|   28|\n",
      "| this fact. ▷ 참고:...|    1|\n",
      "|   ['Economic policy']|    4|\n",
      "|  ['Anthracite coal...|    2|\n",
      "|   Washington State...|    1|\n",
      "|            2019-08-22|    1|\n",
      "|  ['Gettysburg (Pa.)']|    1|\n",
      "|                 beans|    1|\n",
      "+----------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_df.groupBy(\"Title\").count().show()\n",
    "books_df.groupBy(\"categories\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4fff72fc-78f9-4820-8e6b-00e4ea8a8401",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|distinct_publishers|distinct_categories|\n",
      "+-------------------+-------------------+\n",
      "|              34264|              28361|\n",
      "+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distinct_counts_df = books_df.agg(\n",
    "    F.countDistinct(\"publisher\").alias(\"distinct_publishers\"),\n",
    "    F.countDistinct(\"categories\").alias(\"distinct_categories\")\n",
    ")\n",
    "\n",
    "distinct_counts_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcf5b77-5734-41cd-98fc-357f19fda919",
   "metadata": {},
   "source": [
    "> **Book Categories Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "be3ce724-0681-458c-8fb8-f66300ddae7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|          categories|count|\n",
      "+--------------------+-----+\n",
      "|         ['Fiction']|19970|\n",
      "|             Unknown|15672|\n",
      "|         ['History']| 7873|\n",
      "|        ['Religion']| 7871|\n",
      "|['Juvenile Fiction']| 6081|\n",
      "|['Biography & Aut...| 5200|\n",
      "|['Business & Econ...| 4659|\n",
      "|       ['Computers']| 3656|\n",
      "|  ['Social Science']| 3206|\n",
      "|['Juvenile Nonfic...| 3184|\n",
      "|         ['Science']| 2341|\n",
      "|       ['Education']| 2291|\n",
      "|         ['Cooking']| 2157|\n",
      "|['Sports & Recrea...| 1971|\n",
      "|         ['Medical']| 1828|\n",
      "|['Family & Relati...| 1810|\n",
      "|           ['Music']| 1798|\n",
      "|             ['Art']| 1795|\n",
      "|['Literary Critic...| 1786|\n",
      "|['Language Arts &...| 1750|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category_counts = books_df.groupBy(\"categories\").count().orderBy(col(\"count\").desc())\n",
    "category_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9359ae8-23db-4cdd-b2e5-f7a83b32a8e7",
   "metadata": {},
   "source": [
    "> **Authors Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "84208858-c7a5-411f-b78a-4ff6cae3e932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|             authors|count|\n",
      "+--------------------+-----+\n",
      "|             Unknown| 6903|\n",
      "| we issue the boo...|  252|\n",
      "|       ['Rose Arny']|  235|\n",
      "|['Library of Cong...|  178|\n",
      "|['William Shakesp...|  177|\n",
      "| ['Agatha Christie']|  133|\n",
      "|['Erle Stanley Ga...|  116|\n",
      "|\"[\"\"Louis L'Amour...|  115|\n",
      "| ['Charles Dickens']|   79|\n",
      "|['Edgar Rice Burr...|   71|\n",
      "|   ['Carolyn Keene']|   70|\n",
      "|   ['Ann M. Martin']|   66|\n",
      "| ['Rudyard Kipling']|   64|\n",
      "|    ['Isaac Asimov']|   64|\n",
      "|       ['Zane Grey']|   63|\n",
      "|    ['Nora Roberts']|   59|\n",
      "|      ['Mark Twain']|   56|\n",
      "|     ['Henry James']|   53|\n",
      "|   ['Joseph Conrad']|   53|\n",
      "|['Arthur James We...|   52|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count books per author\n",
    "author_counts = books_df.groupBy(\"authors\").count().orderBy(col(\"count\").desc())\n",
    "author_counts.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef92daaa-5d03-48d7-a2ab-86855644e4a3",
   "metadata": {},
   "source": [
    "> **Publisher Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "88a6cc44-0de2-4395-af39-b933814a5b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|           publisher|count|\n",
      "+--------------------+-----+\n",
      "|             Unknown|48575|\n",
      "|  Simon and Schuster| 2943|\n",
      "|             Penguin| 2304|\n",
      "|           Routledge| 2149|\n",
      "|   John Wiley & Sons| 1671|\n",
      "|      Harper Collins| 1504|\n",
      "|Cambridge Univers...| 1451|\n",
      "|           Macmillan| 1059|\n",
      "|     Open Road Media|  974|\n",
      "| Courier Corporation|  967|\n",
      "|Houghton Mifflin ...|  836|\n",
      "|             Vintage|  820|\n",
      "|        Random House|  776|\n",
      "|Springer Science ...|  739|\n",
      "|           iUniverse|  689|\n",
      "|Oxford University...|  640|\n",
      "|Oxford University...|  638|\n",
      "|         Hachette UK|  518|\n",
      "|       HarperCollins|  495|\n",
      "|           Harlequin|  495|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count books per publisher\n",
    "publisher_counts = books_df.groupBy(\"publisher\").count().orderBy(col(\"count\").desc())\n",
    "publisher_counts.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c58c75be-aa89-429c-a6b9-5368890f7c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|Year|count|\n",
      "+----+-----+\n",
      "| \"\" |    6|\n",
      "| \"\"\"|    3|\n",
      "| \"\"'|    1|\n",
      "| \"\"-|    1|\n",
      "| \"\"A|    8|\n",
      "| \"\"C|    5|\n",
      "| \"\"D|    2|\n",
      "| \"\"E|    1|\n",
      "| \"\"F|    2|\n",
      "| \"\"G|    2|\n",
      "| \"\"H|    5|\n",
      "| \"\"I|    3|\n",
      "| \"\"J|    3|\n",
      "| \"\"L|    3|\n",
      "| \"\"M|    3|\n",
      "| \"\"N|    1|\n",
      "| \"\"O|    2|\n",
      "| \"\"P|    4|\n",
      "| \"\"Q|    3|\n",
      "| \"\"R|    2|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count books per year\n",
    "year_counts = books_df.groupBy(\"Year\").count().orderBy(\"Year\")\n",
    "year_counts.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2a704c6e-e343-42d2-8f98-c52fe7051c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|          categories|       avg_ratings|\n",
      "+--------------------+------------------+\n",
      "| ['Charity-schools']|            2634.0|\n",
      "|['Abnormalities, ...|2576.0788011550903|\n",
      "|HMH Books For You...|            2020.0|\n",
      "|    Houghton Mifflin|            2019.0|\n",
      "|                Mack|            2019.0|\n",
      "|Arthur A. Levine ...|            2014.0|\n",
      "|Knopf Books for Y...|            2014.0|\n",
      "|Sterling Publishe...|            2013.0|\n",
      "|       Jonathan Cape|            2013.0|\n",
      "|         Arena Press|            2013.0|\n",
      "|      Signet Classic|            2013.0|\n",
      "|    Penn State Press|            2012.0|\n",
      "|Penguin Young Rea...|            2012.0|\n",
      "|       Templar Books|            2012.0|\n",
      "|            Raintree|            2012.0|\n",
      "| Gryphon House, Inc.|            2012.0|\n",
      "|Carnelian Heart P...|            2012.0|\n",
      "|        Amacom Books|            2011.0|\n",
      "|       Watermark Pub|            2011.0|\n",
      "|Carson Dellosa Pu...|            2011.0|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+-----------+\n",
      "|           publisher|avg_ratings|\n",
      "+--------------------+-----------+\n",
      "| Techpr Incorporated|     3387.0|\n",
      "|Black Swan/Carous...|     3302.0|\n",
      "|      ['Steve Foxe']|     2021.0|\n",
      "| ['James L. Gelvin']|     2020.0|\n",
      "|['Guiseppe Getto'...|     2020.0|\n",
      "|      ['Traci Chee']|     2020.0|\n",
      "|   ['Bryce Andrews']|     2019.0|\n",
      "|  ['Collier Schorr']|     2019.0|\n",
      "|['Lorraine Hedtke...|     2017.0|\n",
      "|       ['Alan Drew']|     2017.0|\n",
      "|     ['Yoko Nogiri']|     2016.0|\n",
      "|     ['Lynn Downey']|     2016.0|\n",
      "|['Blazing Ink, In...|     2015.0|\n",
      "| ['Stewart Sifakis']|     2014.0|\n",
      "|       ['Shaun Tan']|     2014.0|\n",
      "|     ['Edna Ferber']|     2014.0|\n",
      "|['Charles Stangor...|     2014.0|\n",
      "|['Pat Mora', 'Lib...|     2014.0|\n",
      "|   ['Jane Rogoyska']|     2013.0|\n",
      "|     ['Priti Mehta']|     2013.0|\n",
      "+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# Calculate average ratings per category\n",
    "avg_ratings_per_category = books_df.groupBy(\"categories\").agg(avg(\"ratingsCount\").alias(\"avg_ratings\")).orderBy(\"avg_ratings\", ascending=False)\n",
    "avg_ratings_per_category.show()\n",
    "\n",
    "# Calculate average ratings per publisher\n",
    "avg_ratings_per_publisher = books_df.groupBy(\"publisher\").agg(avg(\"ratingsCount\").alias(\"avg_ratings\")).orderBy(\"avg_ratings\", ascending=False)\n",
    "avg_ratings_per_publisher.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "cfc2ddc9-571d-4ee1-a1ba-a02c4f53499c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----------------+\n",
      "|             authors|count|      avg_ratings|\n",
      "+--------------------+-----+-----------------+\n",
      "|  ['Barbara Melosh']|    1|56.31520462036133|\n",
      "|    ['Donald Cline']|    1|56.31520462036133|\n",
      "|     ['Dian Layton']|    2|56.31520462036133|\n",
      "| ['Sergius Golowin']|    1|56.31520462036133|\n",
      "|       ['Kotoyama,']|    1|56.31520462036133|\n",
      "|   ['Joseph Kerman']|    1|56.31520462036133|\n",
      "|     ['Kay Flowers']|    1|56.31520462036133|\n",
      "|     ['John Rewald']|    3|56.31520462036133|\n",
      "|\"\" To a very stro...|    1|56.31520462036133|\n",
      "|['I. Ristic', 'Ia...|    1|56.31520462036133|\n",
      "|['Andrew P. Tobias']|    3|56.31520462036133|\n",
      "|['Judith Ennamora...|    2|56.31520462036133|\n",
      "|['Jamgon Kongtrul...|    1|56.31520462036133|\n",
      "|['Frank Miller', ...|    1|56.31520462036133|\n",
      "|['National Resear...|    1|56.31520462036133|\n",
      "| all of whom were...|    1|56.31520462036133|\n",
      "|['William B. Park...|    1|56.31520462036133|\n",
      "|      ['Max Fogiel']|    3|56.31520462036133|\n",
      "|      ['Jules Bass']|    1|56.31520462036133|\n",
      "|  ['Rebecca Harvin']|    1|56.31520462036133|\n",
      "+--------------------+-----+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count books per author\n",
    "books_per_author = books_df.groupBy(\"authors\").count().orderBy(col(\"count\").desc())\n",
    "\n",
    "# Calculate average ratings per author\n",
    "avg_ratings_per_author = books_df.groupBy(\"authors\").agg(avg(\"ratingsCount\").alias(\"avg_ratings\")).orderBy(\"avg_ratings\", ascending=False)\n",
    "\n",
    "# Join to get both counts and average ratings\n",
    "top_authors_analysis = books_per_author.join(avg_ratings_per_author, \"authors\")\n",
    "top_authors_analysis.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "84ace961-56a3-4b83-9168-39ea32fba086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               Title|        authors_list|\n",
      "+--------------------+--------------------+\n",
      "|\"\"\" We'll Always ...|[['Robert A. Nowl...|\n",
      "|\"\"\"Always ready!\"...|[&dq=%22Always+re...|\n",
      "|\"\"\"Billboard\"\" Bo...|          [ country]|\n",
      "|\"\"\"Carefree\"\" (R....|[['Allan Scott', ...|\n",
      "|\"\"\"Catch 'em aliv...|[ John R. Abernat...|\n",
      "|      \"\"\"Cleanliness|[ (Pointers for l...|\n",
      "|\"\"\"Could Be Worse...|[['James Stevenso...|\n",
      "|\"\"\"Gentlemen pref...|[ forging a new a...|\n",
      "|          \"\"\"Gizelle|[Tells the story ...|\n",
      "|\"\"\"Glory is a-com...|[['Martha Peterso...|\n",
      "|\"\"\"I Do\"\"...Weddi...|           [Unknown]|\n",
      "|    \"\"\"James Bowie\"\"|[\",,['Evelyn Brog...|\n",
      "|\"\"\"Little Rainman...|[['Karen L. Simmo...|\n",
      "|\"\"\"Nothing but pr...|           [Unknown]|\n",
      "|\"\"\"Our Brown-Eyed...|[['Jeffrey McAndr...|\n",
      "|\"\"\"Pet Shop Boys\"...|   [['Chris Heath']]|\n",
      "|\"\"\"Purse\"\"onalize...|[['Andrews McMeel...|\n",
      "|          \"\"\"Sweeps\"|         [ Barbados]|\n",
      "|\"\"\"The Jukes\"\": A...|[ Disease and Her...|\n",
      "|\"\"\"To whom the go...|[['Diana Maud Nin...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+--------------------+\n",
      "|               Title|     categories_list|\n",
      "+--------------------+--------------------+\n",
      "|\"\"\" We'll Always ...|     [['Reference']]|\n",
      "|\"\"\"Always ready!\"...|           [Unknown]|\n",
      "|\"\"\"Billboard\"\" Bo...|[http://books.goo...|\n",
      "|\"\"\"Carefree\"\" (R....|           [Unknown]|\n",
      "|\"\"\"Catch 'em aliv...|[ a service for w...|\n",
      "|      \"\"\"Cleanliness|              [1943]|\n",
      "|\"\"\"Could Be Worse...|[['Juvenile Ficti...|\n",
      "|\"\"\"Gentlemen pref...|[http://books.goo...|\n",
      "|          \"\"\"Gizelle|[http://books.goo...|\n",
      "|\"\"\"Glory is a-com...|       [['Indiana']]|\n",
      "|\"\"\"I Do\"\"...Weddi...|[['Business & Eco...|\n",
      "|    \"\"\"James Bowie\"\"|              [1922]|\n",
      "|\"\"\"Little Rainman...|[['Autistic child...|\n",
      "|\"\"\"Nothing but pr...|       [['History']]|\n",
      "|\"\"\"Our Brown-Eyed...|[['Biography & Au...|\n",
      "|\"\"\"Pet Shop Boys\"...|         [['Music']]|\n",
      "|\"\"\"Purse\"\"onalize...|           [Unknown]|\n",
      "|          \"\"\"Sweeps\"|  [['Cherie Jones']]|\n",
      "|\"\"\"The Jukes\"\": A...|           [Unknown]|\n",
      "|\"\"\"To whom the go...|  [['Horsemanship']]|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+--------------------+\n",
      "|               Title|     publishers_list|\n",
      "+--------------------+--------------------+\n",
      "|\"\"\" We'll Always ...|         [Perennial]|\n",
      "|\"\"\"Always ready!\"...|              [1943]|\n",
      "|\"\"\"Billboard\"\" Bo...|[ and rock record...|\n",
      "|\"\"\"Carefree\"\" (R....|           [Unknown]|\n",
      "|\"\"\"Catch 'em aliv...|[ Secret Service ...|\n",
      "|      \"\"\"Cleanliness|           [Unknown]|\n",
      "|\"\"\"Could Be Worse...|    [Harper Collins]|\n",
      "|\"\"\"Gentlemen pref...|[http://books.goo...|\n",
      "|          \"\"\"Gizelle|[http://books.goo...|\n",
      "|\"\"\"Glory is a-com...|           [Unknown]|\n",
      "|\"\"\"I Do\"\"...Weddi...|[Entrepreneur Press]|\n",
      "|    \"\"\"James Bowie\"\"|[+a+hero+of+the+A...|\n",
      "|\"\"\"Little Rainman...|           [Unknown]|\n",
      "|\"\"\"Nothing but pr...|[Government Print...|\n",
      "|\"\"\"Our Brown-Eyed...|           [Unknown]|\n",
      "|\"\"\"Pet Shop Boys\"...|      [Random House]|\n",
      "|\"\"\"Purse\"\"onalize...|           [Unknown]|\n",
      "|          \"\"\"Sweeps\"|[ and selling the...|\n",
      "|\"\"\"The Jukes\"\": A...|[['Richard Louis ...|\n",
      "|\"\"\"To whom the go...|           [Unknown]|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_set\n",
    "\n",
    "# Common authors between books\n",
    "common_authors_df = books_df.groupBy(\"Title\").agg(collect_set(\"authors\").alias(\"authors_list\"))\n",
    "common_authors_df.show()\n",
    "\n",
    "# Common categories between books\n",
    "common_categories_df = books_df.groupBy(\"Title\").agg(collect_set(\"categories\").alias(\"categories_list\"))\n",
    "common_categories_df.show()\n",
    "\n",
    "# Common publishers between books\n",
    "common_publishers_df = books_df.groupBy(\"Title\").agg(collect_set(\"publisher\").alias(\"publishers_list\"))\n",
    "common_publishers_df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9ec825-628b-4d47-a622-2081a200f6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count books per author\n",
    "books_per_author = books_df.groupBy(\"authors\").count().orderBy(col(\"count\").desc())\n",
    "\n",
    "# Calculate average ratings per author\n",
    "avg_ratings_per_author = books_df.groupBy(\"authors\").agg(avg(\"ratingsCount\").alias(\"avg_ratings\")).orderBy(\"avg_ratings\", ascending=False)\n",
    "\n",
    "# Join to get both counts and average ratings\n",
    "top_authors_analysis = books_per_author.join(avg_ratings_per_author, \"authors\")\n",
    "top_authors_analysis.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99344bbe-b5c8-4023-b466-57e9c12c7ee4",
   "metadata": {},
   "source": [
    "### General Properties of second DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0370dcc5-65e8-4da9-b761-845f62f86a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\abdel\\Downloads\\BigData_Project\\Sales_Data\\Books_rating.csv\"\n",
    "# Read the CSV file into a DataFrame\n",
    "rating_df = spark.read.csv(file_path, header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942987bc-5e6b-4f5c-9228-375fa5e2c70c",
   "metadata": {},
   "source": [
    "> **Show Rating Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b78f2eb4-7041-458f-a3a2-220061a3d324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
      "|        Id|               Title|Price|       User_id|         profileName|review/helpfulness|review/score|review/time|      review/summary|         review/text|\n",
      "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
      "|1882931173|Its Only Art If I...| null| AVCGYZL8FQQTD|\"Jim of Oz \"\"jim-...|               7/7|         4.0|  940636800|Nice collection o...|This is only for ...|\n",
      "|0826414346|Dr. Seuss: Americ...| null|A30TK6U7DNS82R|       Kevin Killian|             10/10|         5.0| 1095724800|   Really Enjoyed It|I don't care much...|\n",
      "|0826414346|Dr. Seuss: Americ...| null|A3UH4UZ4RSVO82|        John Granger|             10/11|         5.0| 1078790400|Essential for eve...|\"If people become...|\n",
      "|0826414346|Dr. Seuss: Americ...| null|A2MVUWT453QH61|\"Roy E. Perry \"\"a...|               7/7|         4.0| 1090713600|Phlip Nel gives s...|Theodore Seuss Ge...|\n",
      "|0826414346|Dr. Seuss: Americ...| null|A22X4XUPKF66MR|\"D. H. Richards \"...|               3/3|         4.0| 1107993600|Good academic ove...|\"Philip Nel - Dr....|\n",
      "|0826414346|Dr. Seuss: Americ...| null|A2F6NONFUDB6UK|              Malvin|               2/2|         4.0| 1127174400|One of America's ...|\"\"\"Dr. Seuss: Ame...|\n",
      "|0826414346|Dr. Seuss: Americ...| null|A14OJS0VWMOSWO| Midwest Book Review|               3/4|         5.0| 1100131200|A memorably excel...|Theodor Seuss Gie...|\n",
      "|0826414346|Dr. Seuss: Americ...| null|A2RSSXTDZDUSH4|           J. Squire|               0/0|         5.0| 1231200000|Academia At It's ...|\"When I recieved ...|\n",
      "|0826414346|Dr. Seuss: Americ...| null|A25MD5I2GUIW6W|\"J. P. HIGBED \"\"b...|               0/0|         5.0| 1209859200|And to think that...|\"Trams (or any pu...|\n",
      "|0826414346|Dr. Seuss: Americ...| null|A3VA4XFS5WNJO3|     Donald Burnside|               3/5|         4.0| 1076371200|Fascinating accou...|As far as I am aw...|\n",
      "|0829814000|Wonderful Worship...|19.40| AZ0IOBU20TBOP|  Rev. Pamela Tinnin|              8/10|         5.0|  991440000|Outstanding Resou...|I just finished t...|\n",
      "|0829814000|Wonderful Worship...|19.40|A373VVEU6Z9M0N|Dr. Terry W. Dorsett|               1/1|         5.0| 1291766400|Small Churches CA...|\"Many small churc...|\n",
      "|0829814000|Wonderful Worship...|19.40| AGKGOH65VTRR4|\"Cynthia L. Lajoy...|               1/1|         5.0| 1248307200|Not Just for Past...|I just finished r...|\n",
      "|0829814000|Wonderful Worship...|19.40| A3OQWLU31BU1Y|       Maxwell Grant|               1/1|         5.0| 1222560000|Small church past...|\"I hadn't been a ...|\n",
      "|0595344550|Whispers of the W...|10.95|A3Q12RK71N74LB|         Book Reader|              7/11|         1.0| 1117065600|            not good|I bought this boo...|\n",
      "|0595344550|Whispers of the W...|10.95|A1E9M6APK30ZAU|           V. Powell|               1/2|         4.0| 1119571200|  Here is my opinion|\"I have to admit,...|\n",
      "|0595344550|Whispers of the W...|10.95| AUR0VA5H0C66C|\"LoveToRead \"\"Act...|               1/2|         1.0| 1119225600|        Buyer beware|\"This is a self-p...|\n",
      "|0595344550|Whispers of the W...|10.95|A1YLDZ3VHR6QPZ|               Clara|               2/4|         5.0| 1115942400| Fall on your knee's|When I first read...|\n",
      "|0595344550|Whispers of the W...|10.95| ACO23CG8K8T77|               Tonya|               5/9|         5.0| 1117065600|      Bravo Veronica|I read the review...|\n",
      "|0595344550|Whispers of the W...|10.95|A1VK81CRRC7MLM|\"missyLou \"\"apple\"\"\"|               1/3|         5.0| 1130025600|           Wonderful|\"I really enjoyed...|\n",
      "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8a76e62c-5038-4f51-8118-1a200fe12e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Price: string (nullable = true)\n",
      " |-- User_id: string (nullable = true)\n",
      " |-- profileName: string (nullable = true)\n",
      " |-- review/helpfulness: string (nullable = true)\n",
      " |-- review/score: string (nullable = true)\n",
      " |-- review/time: string (nullable = true)\n",
      " |-- review/summary: string (nullable = true)\n",
      " |-- review/text: string (nullable = true)\n",
      "\n",
      "Count of dataframe: 3000000\n"
     ]
    }
   ],
   "source": [
    "rating_df.printSchema()\n",
    "print(\"Count of dataframe:\",rating_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a04755a1-3d94-4125-8e35-9188a4e607a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+-------------------+-----------+-------------------+------------------+--------------------+--------------------+--------------------+\n",
      "|summary|                  Id|               Title|               Price|            User_id|profileName| review/helpfulness|      review/score|         review/time|      review/summary|         review/text|\n",
      "+-------+--------------------+--------------------+--------------------+-------------------+-----------+-------------------+------------------+--------------------+--------------------+--------------------+\n",
      "|  count|             3000000|             2999792|              482421|            2437750|    2437800|            2999633|           2999870|             2999973|             2999935|             2999957|\n",
      "|   mean|1.0568515696607149E9|   2012.796651763537|  21.767951161877054|  18.29299003322259|        NaN|3.285048033703448E8| 1656.860421970827|1.1270533345949814E9|            Infinity|  9.95368319174848E8|\n",
      "| stddev| 1.284488524833734E9|  1536.7533549608797|   26.21155241772817|  21.99284402625621|        NaN| 5.46938050416698E8|1427549.9863179324|1.6715719402140123E8|                 NaN| 4.227222142880359E8|\n",
      "|    min|          0001047604|  \"\"\" Film technique|              \"\" and| \"\" Film acting \"\"\"|          \u001a|      #1 Bestse...\"|   & Algorithms\"\"\"| \"\"Cards of your ...| \"\"The Child Manu...|\u0011The Tao of Muham...|\n",
      "|    max|          B0064P287I|you can do anythi...|: A guide to loca...|      AZZZZW74AAX75|    ~~~~~~~|                 xo|         thersites|        sideshowmatt|~~~~~~~~~~~~~~~~~...|~~~~~~~~~~~~~~~~~...|\n",
      "+-------+--------------------+--------------------+--------------------+-------------------+-----------+-------------------+------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fd7c8c-9b1b-4e49-8b9f-c117876ba342",
   "metadata": {},
   "source": [
    "## Data Cleaning 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "062bb223-62ff-47e2-b62f-72c5067d3759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in each column:\n",
      "Id: 0\n",
      "Title: 208\n",
      "Price: 2519269\n",
      "User_id: 562250\n",
      "profileName: 562200\n",
      "review/helpfulness: 367\n",
      "review/score: 18064\n",
      "review/time: 4732\n",
      "review/summary: 65\n",
      "review/text: 43\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum as spark_sum\n",
    "\n",
    "null_counts = rating_df.agg(*[spark_sum(col(c).isNull().cast(\"int\")).alias(c + '_null_count') for c in rating_df.columns])\n",
    "null_counts_single_row = null_counts.collect()[0]\n",
    "print(\"Number of null values in each column:\")\n",
    "for col_name in rating_df.columns:\n",
    "    print(f\"{col_name}: {null_counts_single_row[col_name + '_null_count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "08f79646-c233-4770-8567-084ff8199dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df= rating_df.dropna(subset=['Title'])\n",
    "rating_df= rating_df.dropna(subset=['User_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "353f079e-59a7-4e7d-9a48-ff347fd806bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "\n",
    "# Calculate mean value for a column\n",
    "mean_value = rating_df.select(mean(col('Price'))).collect()[0][0]\n",
    "\n",
    "# Fill missing values with mean\n",
    "rating_df = rating_df.fillna(mean_value, subset=['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "36797262-1b8c-4e22-8139-597961305a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill null values in 'profileName' column with 'Anonymous'\n",
    "default_value = \"Anonymous\"\n",
    "rating_df = rating_df.fillna(default_value, subset=['profileName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "980cc6c8-fdd6-49fe-810c-71e6d400afd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill null values in 'review/summary' column with 'No Summary'\n",
    "default_value = \"No Summary\"\n",
    "default_value2 = \"No Text\"\n",
    "rating_df = rating_df.fillna(default_value, subset=['review/summary'])\n",
    "rating_df = rating_df.fillna(default_value, subset=['review/text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f028432c-0b8a-447e-a14c-454cc774fd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'review/helpfulness': 0\n",
      "Number of null values in 'review/score': 0\n",
      "Number of null values in 'review/time': 0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Define the columns to check\n",
    "cols_to_check = [\"review/helpfulness\", \"review/score\", \"review/time\"]\n",
    "\n",
    "# Create a dictionary to store mode values for each column\n",
    "mode_values = {}\n",
    "\n",
    "# Find the most frequent value for each column\n",
    "for col_name in cols_to_check:\n",
    "    mode_value = rating_df.groupBy(col_name).count() \\\n",
    "                         .orderBy(col(\"count\").desc()) \\\n",
    "                         .select(col_name) \\\n",
    "                         .first()[0]\n",
    "    mode_values[col_name] = mode_value\n",
    "\n",
    "# Fill null values with the most frequent value for each column\n",
    "for col_name, mode_value in mode_values.items():\n",
    "    rating_df = rating_df.withColumn(col_name, when(col(col_name).isNull(), mode_value).otherwise(col(col_name)))\n",
    "\n",
    "# Check the number of null values after filling\n",
    "null_counts_after = {col_name: rating_df.where(col(col_name).isNull()).count() for col_name in cols_to_check}\n",
    "\n",
    "# Show the updated counts of null values\n",
    "for col_name, null_count in null_counts_after.items():\n",
    "    print(f\"Number of null values in '{col_name}': {null_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "02c29c6e-7b52-44d2-8415-4ff94bbbb9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null percentage in column 'Id': 0.00%\n",
      "Null percentage in column 'Title': 0.00%\n",
      "Null percentage in column 'Price': 0.00%\n",
      "Null percentage in column 'User_id': 0.00%\n",
      "Null percentage in column 'profileName': 0.00%\n",
      "Null percentage in column 'review/helpfulness': 0.00%\n",
      "Null percentage in column 'review/score': 0.00%\n",
      "Null percentage in column 'review/time': 0.00%\n",
      "Null percentage in column 'review/summary': 0.00%\n",
      "Null percentage in column 'review/text': 0.00%\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "total_rows = rating_df.count()\n",
    "null_percentages = []\n",
    "for col_name in rating_df.columns:\n",
    "    null_count = rating_df.where(col(col_name).isNull()).count()\n",
    "    null_percentage = (null_count / total_rows) * 100\n",
    "    null_percentages.append((col_name, null_percentage))\n",
    "\n",
    "# Print null percentages\n",
    "for col_name, percentage in null_percentages:\n",
    "    print(f\"Null percentage in column '{col_name}': {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8074e4f0-7907-41f7-a3fc-7a85fae0dbc5",
   "metadata": {},
   "source": [
    "> **Apply ETL => Transform Step** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9e04df02-8ced-46d3-a098-0eb371caa748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Price: float (nullable = true)\n",
      " |-- User_id: string (nullable = true)\n",
      " |-- profileName: string (nullable = true)\n",
      " |-- review/helpfulness: string (nullable = true)\n",
      " |-- review/score: float (nullable = true)\n",
      " |-- review/time: integer (nullable = true)\n",
      " |-- review/summary: string (nullable = true)\n",
      " |-- review/text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "# Convert Price column to float\n",
    "rating_df = rating_df.withColumn(\"Price\", col(\"Price\").cast(\"float\"))\n",
    "# Convert review/score column to float\n",
    "rating_df = rating_df.withColumn(\"review/score\", col(\"review/score\").cast(\"float\"))\n",
    "# Convert review/time column to int\n",
    "rating_df = rating_df.withColumn(\"review/time\", col(\"review/time\").cast(\"int\"))\n",
    "# Check the schema to verify the data type conversions\n",
    "rating_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "eff51315-9c3d-4ec2-b4d4-b47b8a62ef0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+---------+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
      "|        Id|               Title|    Price|       User_id|        profile_Name|review_helpfulness|review_score|review_time|      review_summary|         review_text|\n",
      "+----------+--------------------+---------+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
      "|1882931173|Its Only Art If I...|21.768013| AVCGYZL8FQQTD|\"Jim of Oz \"\"jim-...|               7/7|         4.0|  940636800|Nice collection o...|This is only for ...|\n",
      "|0826414346|Dr. Seuss: Americ...|21.768013|A30TK6U7DNS82R|       Kevin Killian|             10/10|         5.0| 1095724800|   Really Enjoyed It|I don't care much...|\n",
      "|0826414346|Dr. Seuss: Americ...|21.768013|A3UH4UZ4RSVO82|        John Granger|             10/11|         5.0| 1078790400|Essential for eve...|\"If people become...|\n",
      "|0826414346|Dr. Seuss: Americ...|21.768013|A2MVUWT453QH61|\"Roy E. Perry \"\"a...|               7/7|         4.0| 1090713600|Phlip Nel gives s...|Theodore Seuss Ge...|\n",
      "|0826414346|Dr. Seuss: Americ...|21.768013|A22X4XUPKF66MR|\"D. H. Richards \"...|               3/3|         4.0| 1107993600|Good academic ove...|\"Philip Nel - Dr....|\n",
      "|0826414346|Dr. Seuss: Americ...|21.768013|A2F6NONFUDB6UK|              Malvin|               2/2|         4.0| 1127174400|One of America's ...|\"\"\"Dr. Seuss: Ame...|\n",
      "|0826414346|Dr. Seuss: Americ...|21.768013|A14OJS0VWMOSWO| Midwest Book Review|               3/4|         5.0| 1100131200|A memorably excel...|Theodor Seuss Gie...|\n",
      "|0826414346|Dr. Seuss: Americ...|21.768013|A2RSSXTDZDUSH4|           J. Squire|               0/0|         5.0| 1231200000|Academia At It's ...|\"When I recieved ...|\n",
      "|0826414346|Dr. Seuss: Americ...|21.768013|A25MD5I2GUIW6W|\"J. P. HIGBED \"\"b...|               0/0|         5.0| 1209859200|And to think that...|\"Trams (or any pu...|\n",
      "|0826414346|Dr. Seuss: Americ...|21.768013|A3VA4XFS5WNJO3|     Donald Burnside|               3/5|         4.0| 1076371200|Fascinating accou...|As far as I am aw...|\n",
      "|0829814000|Wonderful Worship...|     19.4| AZ0IOBU20TBOP|  Rev. Pamela Tinnin|              8/10|         5.0|  991440000|Outstanding Resou...|I just finished t...|\n",
      "|0829814000|Wonderful Worship...|     19.4|A373VVEU6Z9M0N|Dr. Terry W. Dorsett|               1/1|         5.0| 1291766400|Small Churches CA...|\"Many small churc...|\n",
      "|0829814000|Wonderful Worship...|     19.4| AGKGOH65VTRR4|\"Cynthia L. Lajoy...|               1/1|         5.0| 1248307200|Not Just for Past...|I just finished r...|\n",
      "|0829814000|Wonderful Worship...|     19.4| A3OQWLU31BU1Y|       Maxwell Grant|               1/1|         5.0| 1222560000|Small church past...|\"I hadn't been a ...|\n",
      "|0595344550|Whispers of the W...|    10.95|A3Q12RK71N74LB|         Book Reader|              7/11|         1.0| 1117065600|            not good|I bought this boo...|\n",
      "|0595344550|Whispers of the W...|    10.95|A1E9M6APK30ZAU|           V. Powell|               1/2|         4.0| 1119571200|  Here is my opinion|\"I have to admit,...|\n",
      "|0595344550|Whispers of the W...|    10.95| AUR0VA5H0C66C|\"LoveToRead \"\"Act...|               1/2|         1.0| 1119225600|        Buyer beware|\"This is a self-p...|\n",
      "|0595344550|Whispers of the W...|    10.95|A1YLDZ3VHR6QPZ|               Clara|               2/4|         5.0| 1115942400| Fall on your knee's|When I first read...|\n",
      "|0595344550|Whispers of the W...|    10.95| ACO23CG8K8T77|               Tonya|               5/9|         5.0| 1117065600|      Bravo Veronica|I read the review...|\n",
      "|0595344550|Whispers of the W...|    10.95|A1VK81CRRC7MLM|\"missyLou \"\"apple\"\"\"|               1/3|         5.0| 1130025600|           Wonderful|\"I really enjoyed...|\n",
      "+----------+--------------------+---------+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating_df = rating_df.withColumnRenamed('profileName', 'profile_Name') \\\n",
    "                             .withColumnRenamed('review/helpfulness', 'review_helpfulness')\\\n",
    "                             .withColumnRenamed('review/score', 'review_score')\\\n",
    "                             .withColumnRenamed('review/time', 'review_time') \\\n",
    "                             .withColumnRenamed('review/summary', 'review_summary')\\\n",
    "                             .withColumnRenamed('review/text', 'review_text')\n",
    "rating_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edaadd7-5430-4a26-a32f-a3dd4aa53b7a",
   "metadata": {},
   "source": [
    "#### Some Insigths From data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "489a38ec-8012-4bd3-8c53-8dcaa822ddb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|     average_Price|\n",
      "+------------------+\n",
      "|21.768013002900528|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "# Calculate the average age of customers\n",
    "avg_age_df = rating_df.agg(F.avg(\"Price\").alias(\"average_Price\"))\n",
    "avg_age_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a4fb5896-c790-4954-85a6-a5a527f31ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|price_range|        avg_score|\n",
      "+-----------+-----------------+\n",
      "|       18.0| 4.30884070058382|\n",
      "|       64.0|4.086956521739131|\n",
      "|       82.0|3.846774193548387|\n",
      "|      107.0|4.153846153846154|\n",
      "|       47.0|4.208646616541353|\n",
      "|        9.0|4.222615244180739|\n",
      "|       58.0|4.098615916955017|\n",
      "|        5.0|4.255224147169137|\n",
      "|       39.0|4.094320486815416|\n",
      "|      132.0|3.395348837209302|\n",
      "|       30.0|4.159679878048781|\n",
      "|       17.0|4.318933333333334|\n",
      "|      105.0|4.149779735682819|\n",
      "|      163.0|4.681818181818182|\n",
      "|      117.0|4.323076923076923|\n",
      "|      190.0|4.352941176470588|\n",
      "|      187.0|4.478260869565218|\n",
      "|       90.0|4.264044943820225|\n",
      "|       26.0|4.242635523792923|\n",
      "|       41.0|4.053484602917342|\n",
      "+-----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate average review scores per price range\n",
    "price_range_scores = rating_df.groupBy(F.round(\"Price\", 0).alias(\"price_range\")).agg(\n",
    "    F.avg(\"review_score\").alias(\"avg_score\")\n",
    ")\n",
    "\n",
    "price_range_scores.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1c8da3bf-de4c-4b82-81fe-d2af8c47b64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|       User_id|count|\n",
      "+--------------+-----+\n",
      "|A14OJS0VWMOSWO| 5791|\n",
      "|   AFVQZQ8PW0L| 3606|\n",
      "|A1D2C0WDCSHUWZ| 3145|\n",
      "| AHD101501WCN1| 1994|\n",
      "|A1X8VZWTOG8IS6| 1803|\n",
      "|A1K1JW1C5CUSUZ| 1455|\n",
      "|A20EEWWSFMZ1PN| 1387|\n",
      "|A1S3C5OFU508P3| 1307|\n",
      "|A1N1YEMTI9DJ86| 1030|\n",
      "|A2OJW07GQRNJUT|  999|\n",
      "|A1L43KWWR05PCS|  960|\n",
      "|A1G37DFO8MQW0M|  932|\n",
      "|A2NJO6YE954DBH|  913|\n",
      "|A3M174IC0VXOS2|  912|\n",
      "|A1EKTLUL24HDG8|  900|\n",
      "|A3MV1KKHX51FYT|  866|\n",
      "|A3QVAKVRAH657N|  824|\n",
      "|A1M8PP7MLHNBQB|  798|\n",
      "|A319KYEIAZ3SON|  797|\n",
      "|A1MC6BFHWY6WC3|  780|\n",
      "+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|  review_helpfulness|count|\n",
      "+--------------------+-----+\n",
      "|       #1 Bestse...\"|    2|\n",
      "|    & it will be.\"\"\"|    7|\n",
      "| &#34; red book ...\"|    7|\n",
      "| &#34;Attract Mon...|    2|\n",
      "|     &#34;Author...\"|    2|\n",
      "| &#34;Copywriting...|   12|\n",
      "|     &#34;Human ...\"|    1|\n",
      "| &#34;If I'm So S...|    3|\n",
      "| &#34;Infinity's ...|    1|\n",
      "| &#34;Jesus Died ...|    6|\n",
      "| &#34;Kaleidoscop...|    1|\n",
      "| &#34;Land Beyond...|    1|\n",
      "|     &#34;Listen...\"|    2|\n",
      "| &#34;Making Of A...|    4|\n",
      "| &#34;No Child Le...|   11|\n",
      "|       &#34;Post...\"|    5|\n",
      "| &#34;Shock Thera...|    2|\n",
      "|        &#34;Standby|    1|\n",
      "| &#34;Subject:CIN...|    1|\n",
      "|  &#34;That One ...\"|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count the number of reviews per user\n",
    "user_review_count = rating_df.groupBy('User_id').count().orderBy('count', ascending=False).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3a240811-219c-45bd-9638-a8a5b47bed69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|Price| avg(review_score)|\n",
      "+-----+------------------+\n",
      "|  1.0| 4.120765832106038|\n",
      "| 1.09|             4.385|\n",
      "| 1.19|               3.0|\n",
      "| 1.25|               4.0|\n",
      "| 1.29|4.0144927536231885|\n",
      "| 1.35| 4.082417582417582|\n",
      "| 1.38|               4.0|\n",
      "| 1.39|              3.75|\n",
      "| 1.49|  4.23314606741573|\n",
      "|  1.5| 4.035460992907802|\n",
      "| 1.59| 4.215277777777778|\n",
      "|  1.6| 4.555555555555555|\n",
      "| 1.69|3.9153094462540716|\n",
      "|  1.7| 4.666666666666667|\n",
      "| 1.78|               5.0|\n",
      "| 1.79| 4.211538461538462|\n",
      "|  1.8| 4.514285714285714|\n",
      "| 1.82| 4.205882352941177|\n",
      "| 1.86|               5.0|\n",
      "| 1.88|3.7142857142857144|\n",
      "+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate average review score for different price ranges\n",
    "price_scores = rating_df.groupBy('Price').avg('review_score').orderBy('Price').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a51c5f3c-5b0a-4d1e-96d2-e35dcc8e8ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|month| count|\n",
      "+-----+------+\n",
      "|    1|315708|\n",
      "|    2|237857|\n",
      "|    3|194236|\n",
      "|    4|170404|\n",
      "|    5|178797|\n",
      "|    6|171487|\n",
      "|    7|180524|\n",
      "|    8|185697|\n",
      "|    9|183201|\n",
      "|   10|187978|\n",
      "|   11|192820|\n",
      "|   12|238846|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Assuming Books_rating_df is your Spark DataFrame\n",
    "rating_df = rating_df.withColumn(\"review_date\", F.to_date(F.from_unixtime(\"review_time\")))\n",
    "\n",
    "# Calculate review counts per month\n",
    "reviews_per_month = rating_df.groupBy(F.month(\"review_date\").alias(\"month\")).count().orderBy(\"month\")\n",
    "\n",
    "reviews_per_month.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f59608e8-9e2c-4024-af9c-4cb627777315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+------------+\n",
      "|review_time|review_year|review_month|\n",
      "+-----------+-----------+------------+\n",
      "|  940636800|       1999|          10|\n",
      "| 1095724800|       2004|           9|\n",
      "| 1078790400|       2004|           3|\n",
      "| 1090713600|       2004|           7|\n",
      "| 1107993600|       2005|           2|\n",
      "| 1127174400|       2005|           9|\n",
      "| 1100131200|       2004|          11|\n",
      "| 1231200000|       2009|           1|\n",
      "| 1209859200|       2008|           5|\n",
      "| 1076371200|       2004|           2|\n",
      "|  991440000|       2001|           6|\n",
      "| 1291766400|       2010|          12|\n",
      "| 1248307200|       2009|           7|\n",
      "| 1222560000|       2008|           9|\n",
      "| 1117065600|       2005|           5|\n",
      "| 1119571200|       2005|           6|\n",
      "| 1119225600|       2005|           6|\n",
      "| 1115942400|       2005|           5|\n",
      "| 1117065600|       2005|           5|\n",
      "| 1130025600|       2005|          10|\n",
      "+-----------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, month, to_timestamp\n",
    "\n",
    "# Assuming 'review_time' is in seconds since epoch (Unix timestamp)\n",
    "rating_df = rating_df.withColumn('review_time_timestamp', to_timestamp(rating_df['review_time']))\n",
    "\n",
    "# Extract year and month from review time\n",
    "rating_df = rating_df.withColumn('review_year', year(rating_df['review_time_timestamp']))\n",
    "rating_df = rating_df.withColumn('review_month', month(rating_df['review_time_timestamp']))\n",
    "\n",
    "# Drop the intermediate timestamp column if no longer needed\n",
    "rating_df = rating_df.drop('review_time_timestamp')\n",
    "\n",
    "# Show the updated DataFrame\n",
    "rating_df.select('review_time', 'review_year', 'review_month').show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "819710ba-7229-4d61-9485-fd472a45341c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|price_range|avg(review_score)|\n",
      "+-----------+-----------------+\n",
      "|       High|4.133490109282058|\n",
      "|        Low|2049.405812145332|\n",
      "|     Medium|4.211609039984547|\n",
      "+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Create price ranges and categorize items\n",
    "rating_df = rating_df.withColumn('price_range', when(rating_df['Price'] < 50, 'Low')\n",
    "                                  .when((rating_df['Price'] >= 50) & (rating_df['Price'] <= 100), 'Medium')\n",
    "                                  .otherwise('High'))\n",
    "\n",
    "# Analyze distribution of review scores across price ranges\n",
    "price_range_scores = rating_df.groupBy('price_range').avg('review_score').orderBy('price_range').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f4f4f164-a197-49b3-9f7b-c30083b163f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|       User_id|count|\n",
      "+--------------+-----+\n",
      "|A14OJS0VWMOSWO| 5791|\n",
      "|   AFVQZQ8PW0L| 3606|\n",
      "|A1D2C0WDCSHUWZ| 3145|\n",
      "| AHD101501WCN1| 1994|\n",
      "|A1X8VZWTOG8IS6| 1803|\n",
      "|A1K1JW1C5CUSUZ| 1455|\n",
      "|A20EEWWSFMZ1PN| 1387|\n",
      "|A1S3C5OFU508P3| 1307|\n",
      "|A1N1YEMTI9DJ86| 1030|\n",
      "|A2OJW07GQRNJUT|  999|\n",
      "+--------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count the number of reviews per user and identify top reviewers\n",
    "top_reviewers = rating_df.groupBy('User_id').count().orderBy('count', ascending=False).show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e6e4928f-0480-4903-baba-ee62df0d90c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|      text_length|\n",
      "+-------+-----------------+\n",
      "|  count|          2437555|\n",
      "|   mean|622.3102998701568|\n",
      "| stddev|660.0410230129934|\n",
      "|    min|                1|\n",
      "|    max|            32551|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import length\n",
    "\n",
    "# Calculate the length of review text\n",
    "rating_df = rating_df.withColumn('text_length', length(rating_df['review_text']))\n",
    "\n",
    "# Analyze the distribution of review text lengths\n",
    "text_length_stats = rating_df.select('text_length').describe()\n",
    "text_length_stats.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
